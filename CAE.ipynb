{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CAE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rrnbvOcvn44w"},"source":["This is a Google Colab notebook which installs appropriate PyTorch v1 according to the system architecture and the GPU available.\n","\n","Author:  **Tan-Sy NGUYEN**\n"]},{"cell_type":"code","metadata":{"id":"MKoBrqlaPXr_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596018310936,"user_tz":-120,"elapsed":1427,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}},"outputId":"c86c6666-afeb-477b-d866-81b20210cc8b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RtN00cb0n6hZ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596018310941,"user_tz":-120,"elapsed":1299,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}},"outputId":"5c4b93ba-d41c-4e07-dc42-4cd7ed56858f"},"source":["import torch\n","print(torch.__version__)"],"execution_count":116,"outputs":[{"output_type":"stream","text":["1.5.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jW9T-evMrqds","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596018310943,"user_tz":-120,"elapsed":1236,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}},"outputId":"477d23df-2bff-4097-cd19-e84d3c37e1f1"},"source":["# we will verify that GPU is enabled for this notebook\n","# following should print: CUDA is available!  Training on GPU ...\n","# \n","# if it prints otherwise, then you need to enable GPU: \n","# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n","\n","import torch\n","import numpy as np\n","\n","# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":117,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tKQGml-R_jxP","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596018311968,"user_tz":-120,"elapsed":2210,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}},"outputId":"e6e94bfc-5b5d-459a-b49f-28735f3f5752"},"source":["!nvidia-smi"],"execution_count":118,"outputs":[{"output_type":"stream","text":["Wed Jul 29 10:25:09 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P0    73W / 149W |    925MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VA32GQtL_sS4","colab":{},"executionInfo":{"status":"ok","timestamp":1596018311970,"user_tz":-120,"elapsed":2132,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["import torch, argparse\n","from torch.autograd import Variable\n","from torchvision import datasets\n","from torchvision.utils import make_grid\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torch.utils.data.dataset import Dataset\n","import scipy.io as io\n","\n","import numpy as np\n","from collections import OrderedDict\n","\n","import torch, os\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v4AroTSe_ymC","colab":{},"executionInfo":{"status":"ok","timestamp":1596018311971,"user_tz":-120,"elapsed":2043,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["def loss_fn(sparsecode,  z, z_c, x, recon_x ):\n","    recon_loss = 10 * F.mse_loss(recon_x, x)\n","    express_loss = F.mse_loss(z,z_c)\n","    reg_loss = torch.norm(sparsecode,p='fro')\n","    return recon_loss + express_loss + reg_loss"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2VsgYfMLAFYI","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312352,"user_tz":-120,"elapsed":2394,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["class VAEGT(nn.Module):\n","    def __init__(self, split_ratio, batch_size=1000, num_classes=10, negative_slope=0.1):\n","        super(VAEGT, self).__init__()\n","        self.batch_size = batch_size\n","        self.split_ratio = split_ratio\n","\n","        self.train_size = int(self.split_ratio*self.batch_size)\n","        self.test_size = batch_size - self.train_size\n","\n","        self.num_classes = num_classes\n","        self.negative_slope = negative_slope\n","\n","        # Encoder declaration\n","        self.encoder = nn.Sequential(OrderedDict([\n","            ('layer1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=(1,1))),\n","            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","            ('layer2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1,1))),\n","            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","            ('layer3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(1,1))),\n","            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","            ('layer4', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=(1,1))),\n","            ('relu4', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","        ]))\n","\n","        # Sparse layer declaration\n","        self.sparsecode = torch.nn.Parameter(1.0e-4 *torch.ones(self.test_size, self.train_size).cuda(), requires_grad=True)\n","\n","        # Decoder declaration\n","        self.decoder = nn.Sequential(OrderedDict([\n","            ('layer1',  nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=(1,1))),\n","            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","            ('layer2',  nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=(1,1))),\n","            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","            ('layer3',  nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=(1,1),output_padding=1)),\n","            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n","        ]))\n","\n","        self._init_weights()\n","\n","    def forward(self, x_train, y_train, x_test, y_test):\n","        if self.training:\n","\n","            # Encode input\n","            x = torch.cat([x_train, x_test], dim =0)\n","            z_train = self.encoder(x_train).cuda()\n","            z_train = torch.reshape(z_train,[self.train_size,-1])\n","            z_test = self.encoder(x_test).cuda()\n","            z_test_o = torch.reshape(z_test,[self.test_size,-1])\n","            z = torch.cat([z_train, z_test_o], dim=0)\n","\n","            # Sparse coding\n","            z_test_c = torch.matmul(self.sparsecode, z_train)\n","\n","            # Encode label\n","            y_train_onehot = self._onehot(y_train)\n","            y_test_onehot = self._onehot(y_test)\n","            z_c = torch.cat([z_train, z_test_c], dim=0)\n","            z_c_o = torch.reshape(z_c,[self.batch_size,z_test.shape[1],z_test.shape[2],z_test.shape[3]])\n","          \n","            # Decode\n","            x_c = self.decoder(z_c_o)\n","            return self.sparsecode, z, z_c, x, x_c\n","\n","    def _onehot(self, y):\n","        y_onehot = torch.FloatTensor(y.shape[0], self.num_classes)\n","        y_onehot.zero_()\n","        y_onehot.scatter_(1, y.long(), 1)\n","        return y_onehot\n","\n","    def _init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dGYdTmNJAOIJ","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312355,"user_tz":-120,"elapsed":2371,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["# Accuracy checker: mode \"min\" for loss, mode \"max\" for accuracy\n","class ImproveChecker():\n","\tdef __init__(self, mode='min', best_val=None):\n","\t\tassert mode in ['min', 'max']\n","\t\tself.mode = mode\n","\t\tif best_val is not None:\n","\t\t\tself.best_val = best_val\n","\t\telse:\n","\t\t\tif self.mode=='min':\n","\t\t\t\tself.best_val = np.inf\n","\t\t\telif self.mode=='max':\n","\t\t\t\tself.best_val = 0.0\n","\n","\tdef _check(self, val):\n","\t\tif self.mode=='min':\n","\t\t\tif val < self.best_val:\n","\t\t\t\tprint(\"[%s] Improved from %.4f to %.4f\" % (self.__class__.__name__, self.best_val, val))\n","\t\t\t\tself.best_val = val\n","\t\t\t\treturn True\n","\t\t\telse:\n","\t\t\t\tprint(\"[%s] Not improved from %.4f\" % (self.__class__.__name__, self.best_val))\n","\t\t\t\treturn False\n","\t\telse:\n","\t\t\tif val > self.best_val:\n","\t\t\t\tprint(\"[%s] Improved from %.4f to %.4f\" % (self.__class__.__name__, self.best_val, val))\n","\t\t\t\tself.best_val = val\n","\t\t\t\treturn True\n","\t\t\telse:\n","\t\t\t\tprint(\"[%s] Not improved from %.4f\" % (self.__class__.__name__, self.best_val))\n","\t\t\t\treturn False"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VgGHvxl7ygw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312356,"user_tz":-120,"elapsed":2320,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":[" # Process data\n"," class MyDataset(Dataset):\n","    def __init__(self, mat_path,split_ratio,width,height):       \n","      self.width = width\n","      self.height = height\n","      self.split_ratio=split_ratio\n","      feature = io.loadmat(mat_path,squeeze_me=True)['features']\n","      Label = io.loadmat(mat_path,squeeze_me=True)['Label']\n","\n","      self.images = torch.from_numpy(np.transpose(feature)).type(torch.float)\n","      self.images = torch.reshape(self.images,[len(self.images), self.width, self.height])\n","      self.target = torch.from_numpy(np.transpose(Label)).type(torch.long)\n","      self.data=list(zip(self.images, self.target))\n","\n","      self.train_size = int(self.split_ratio*len(self.data))\n","      self.test_size = len(self.data) - self.train_size\n","      \n","    def _generate(self):\n","      self.train_dataset, self.test_dataset = torch.utils.data.random_split(self.data, [self.train_size, self.test_size])\n","      return self.train_dataset, self.test_dataset\n","      \n","    def __getitem__(self, index):\n","      \n","      images=self.images[index]\n","      target=self.target[index]\n","      return images, target\n","     \n","    def __len__(self):\n","      return len(self.data)\n","\n"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryz0iV6V8Fsd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312687,"user_tz":-120,"elapsed":2625,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["mat_path = ('/content/drive/My Drive/Colab Notebooks/Internship/dataset/umd.mat')\n","split_ratio = 0.9\n","num_classes = 50\n","size= [32,32] #size of input image\n","\n","custom_data = MyDataset(mat_path,split_ratio=split_ratio, width = size[0], height=size[1])\n","data_train, data_test = custom_data._generate()\n","dataloader_train = torch.utils.data.DataLoader(dataset=data_train,\n","                                           num_workers=4,\n","                                           batch_size= len(data_train),\n","                                           pin_memory=True)\n","\n","dataloader_test = torch.utils.data.DataLoader(dataset=data_test,\n","                                           num_workers=4,\n","                                           batch_size= len(data_test),\n","                                           pin_memory=True)"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"chxlLm4MfUO6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312690,"user_tz":-120,"elapsed":2599,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["# Initialize VAE\n","model = VAEGT(split_ratio=split_ratio, batch_size= custom_data.__len__() , num_classes=50)\n","model.cuda()\n","\n","# Optimizers\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# ImproveChecker\n","improvechecker = ImproveChecker(mode='min')\n","\n","num_epoch = 10000 #number of training epoch\n","cal_epoch = 1000 #the epoch in which we calculate the accuracy"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcaJ78AQrF1X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312692,"user_tz":-120,"elapsed":2545,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":[" # Get the parameter (sparse code, weights, biases)\n"," class Getparam():\n","    def __init__(self, param_name = 'sparsecode', model = model):\n","     self.param_name = param_name\n","     self.model = model\n","     self.bool_get= False\n","    def _getparam(self, param_name):\n","      for param_name_get, param in self.model.named_parameters():\n","        if param_name_get == param_name:\n","          self.bool_get = True\n","          print(\"Sucessfully: [%s]\" %(param_name), param.data)\n","      if not self.bool_get:\n","        print(\"Error: [%s] parameter is not defined...\" % param_name)\n","      return True\n"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5ZOKh6To6D9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596018312693,"user_tz":-120,"elapsed":2526,"user":{"displayName":"SY NGUYEN TAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWpkKeV4LgC_-0TiedJJxUyazWXHzK_-ZSTdPs3A=s64","userId":"04241490624615267063"}}},"source":["# Calculate the accuracy\n","class Evaluate():\n","  def __init__(self, coef= model.sparsecode, train_labels = None, test_labels= None):\n","    self.coef= coef\n","    self.train_labels= train_labels\n","    self.test_labels= test_labels\n","    self.class_ = torch.zeros(int(torch.max(self.test_labels)))\n","    self.prediction = torch.zeros(len((self.test_labels)))\n","\n","  def _eval(self):\n","    Coef = torch.abs(self._get_threshold(self.coef.cpu()))\n","    for atom in range(0,len(self.test_labels)):\n","        x = Coef[atom,:]\n","        for l in range(1,torch.max(self.test_labels)+1):\n","            l_idx = np.array([j for j in range(0,len(self.train_labels)) if self.train_labels[j]==l]).astype(int)\n","            self.class_[int(l-1)] = sum(torch.abs(x[l_idx]))\n","        self.prediction[atom] = torch.argmax(self.class_) +1\n","\n","    # self.prediction = np.array(self.prediction)\n","    missrate = self._error_cal(self.test_labels, self.prediction)\n","    accuracy = 1 - missrate\n","    return accuracy\n","\n","  def _error_cal(self, ground_truth, predicted_label):\n","    ground_truth=torch.squeeze(ground_truth,1)\n","    _error_value = (ground_truth != predicted_label).sum().item()\n","    missrate = _error_value/ (ground_truth.shape[0])\n","    return missrate\n","\n","  def _get_threshold(self, coef, ro=0.1):\n","      if ro < 1:\n","          Cp = torch.zeros((coef.shape[0], coef.shape[1]))\n","          sorted,_=torch.sort(-torch.abs(coef), 0)\n","          S = torch.abs(sorted)\n","          _index = torch.argsort(-torch.abs(coef),0)\n","          for i in range(coef.shape[1]):\n","              cL1 = torch.sum(S[:, i], dtype = torch.float)\n","              stop = False\n","              csum = 0\n","              t = 0\n","              while (stop == False):\n","                  csum = csum + S[t, i]\n","                  if csum > ro * cL1:\n","                      stop = True\n","                      Cp[_index[0:t + 1, i], i] = coef[_index[0:t + 1, i], i]\n","                  t = t + 1\n","      else:\n","          Cp = coef\n","\n","      return Cp"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dWLyITDvAge0","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"769fc7fc-a501-46dc-9fa3-c8ba032825d0"},"source":["# Training process\n","model.train()\n","for epoch in range(1, num_epoch):\n","    # Prepare input\n","  for i, (imgs_train, labels_train) in enumerate(dataloader_train): # Dataloader for training set\n","    inputs_train = imgs_train.unsqueeze(1).cuda()\n","    labels_train = labels_train.view(-1, 1)\n","    y_onehot_train = torch.FloatTensor(imgs_train.shape[0], 50)\n","    y_onehot_train.zero_()\n","    y_onehot_train.scatter_(1, labels_train, 1).cuda()\n","\n","  for j , (imgs_test, labels_test) in enumerate(dataloader_test): # Dataloader for testing set\n","    inputs_test = imgs_test.unsqueeze(1).cuda()\n","    labels_test = labels_test.view(-1, 1)\n","    y_onehot_test = torch.FloatTensor(imgs_test.shape[0], 50)\n","    y_onehot_test.zero_()\n","    y_onehot_test.scatter_(1, labels_test, 1).cuda()\n","    \n","    # Training\n","    optimizer.zero_grad()\n","    sparsecode, z, z_c, x, x_c = model(inputs_train, y_onehot_train, inputs_test, y_onehot_test)\n","    loss = loss_fn(sparsecode, z, z_c, x, x_c)\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","  if (epoch % cal_epoch == 0):\n","    # ImproveChecker (check the best result)\n","    print(\"\\n[EPOCH %.3d] Loss: %.6f\" % (epoch, loss.item()))\n","    accuracy= Evaluate(coef= sparsecode, train_labels=labels_train, test_labels=labels_test)._eval()\n","    print(\"=================>_Accuracy: %.6f\" % (accuracy))\n","\n","    # Save checkpoint\n","    if improvechecker._check(loss.item()):\n","      checkpoint = dict(\n","        epoch=epoch,\n","        loss=loss.item(),\n","        state_dict=model.state_dict(),\n","        optimizer=optimizer.state_dict(),\n","      )\n","      save_file = os.path.join('/content/drive/My Drive/Colab Notebooks/Variational-Autoencoder/checkpoints/', \"CAE.pth\")\n","      torch.save(checkpoint, save_file)\n","      print(\"Best checkpoint is saved at %s\" % (save_file))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","[EPOCH 1000] Loss: 8095.990723\n","========================>_Accuracy: 0.861224\n","[ImproveChecker] Improved from inf to 8095.9907\n","Best checkpoint is saved at /content/drive/My Drive/Colab Notebooks/Variational-Autoencoder/checkpoints/CAE.pth\n"],"name":"stdout"}]}]}